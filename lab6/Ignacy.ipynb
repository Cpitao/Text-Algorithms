{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b017e7",
   "metadata": {},
   "source": [
    "## Implementacja wybranych metryk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04afced",
   "metadata": {},
   "source": [
    "### Metryka Levensteina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91bb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be applied to iterables of tokens instead of text as well\n",
    "def levenstein(text1, text2):\n",
    "    n1, n2 = len(text1), len(text2)\n",
    "    A = [[None] * (n1+1) for _ in range(n2+1)]\n",
    "    \n",
    "    A[0][0] = (0, None)\n",
    "    for i in range(1, n1+1):\n",
    "        A[0][i] = (i, (0, i-1))\n",
    "    for j in range(1, n2+1):\n",
    "        A[j][0] = (j, (j-1, 0))\n",
    "    \n",
    "    for i in range(1, n1+1):\n",
    "        for j in range(1, n2+1):\n",
    "            add = 1\n",
    "            if text1[i-1] == text2[j-1]:\n",
    "                add = 0\n",
    "\n",
    "            x = min(A[j-1][i][0]+1, A[j][i-1][0]+1, A[j-1][i-1][0]+add)\n",
    "            if A[j-1][i][0] + 1 == x:\n",
    "                A[j][i] = (x, (j-1, i))\n",
    "            elif A[j][i-1][0] + 1 == x:\n",
    "                A[j][i] = (x, (j, i-1))\n",
    "            else:\n",
    "                A[j][i] = (x, (j-1, i-1))\n",
    "\n",
    "    return A[-1][-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb964e9",
   "metadata": {},
   "source": [
    "### Metryka DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a1b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(text1, text2):\n",
    "    letters1 = set(text1)\n",
    "    letters2 = set(text2)\n",
    "    return 2 * len(letters1.intersection(text2)) / (len(letters1) + len(letters2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ab75f",
   "metadata": {},
   "source": [
    "### Metryka LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7b0fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(text1, text2):\n",
    "    n, m = len(text1), len(text2)\n",
    "    \n",
    "    A = [[None for _ in range(m + 1)] for _ in range(n+1)]\n",
    "    for i in range(n+1):\n",
    "        A[i][0] = 0\n",
    "    for i in range(m+1):\n",
    "        A[0][i] = 0\n",
    "        \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            if text1[i-1] == text2[j-1]:\n",
    "                A[i][j] = A[i-1][j-1] + 1\n",
    "            else:\n",
    "                A[i][j] = max(A[i][j-1], A[i-1][j])\n",
    "    \n",
    "    return A[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b57303",
   "metadata": {},
   "source": [
    "## Jakość klasteryzacji - Rand index (nie mylić z losowym)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f27bfa",
   "metadata": {},
   "source": [
    "Wskaźnik liczony jako łączna liczba par które w obu wynikach są w tym samym klastrze lub w obu wynikach są w różnych klastrach, dzielona przez liczbę par."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb457c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_index(result1, result2):\n",
    "    n = len(result1)\n",
    "    enumerator = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if (result1[i] == result1[j] and result2[i] == result2[j]) or \\\n",
    "               (result1[i] != result1[j] and result2[i] != result2[j]):\n",
    "                enumerator += 1\n",
    "    return enumerator / (n * (n-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d0ff5",
   "metadata": {},
   "source": [
    "## Stoplista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60036bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words(words, top=10):\n",
    "    popularity = {}\n",
    "    for w in words:\n",
    "        popularity[w] = popularity.setdefault(w, 0) + 1\n",
    "    \n",
    "    words = sorted(filter(lambda x: len(x[0]) >= 3, popularity.items()), key=lambda x: x[1], reverse=True)\n",
    "    return words[:min(len(words), top)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "022bef6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('china', 934),\n",
       " ('logistics', 822),\n",
       " ('poland', 820),\n",
       " ('ltd', 781),\n",
       " ('ltd.', 555),\n",
       " ('ul.', 469),\n",
       " ('tel:', 406),\n",
       " ('limited', 387),\n",
       " ('fax:', 375),\n",
       " ('road', 372)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"lines.txt\", \"r\") as f:\n",
    "    full = f.read().lower()\n",
    "    words = full.split()\n",
    "\n",
    "stopwords = get_stop_words(words, 100) # top 100 words, last word here has >100 ocurrences\n",
    "# word and it's count\n",
    "get_stop_words(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d847612",
   "metadata": {},
   "source": [
    "## Klasteryzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a1ad4",
   "metadata": {},
   "source": [
    "Do klasteryzacji wykorzystano algorytm affinity propagation z scikit-learn. Dane po preprocessingu to lista słów, z których usunięto znaki interpunkcyjne. Zastosowanie takich metryk dla danych przed przerobieniem powoduje, że \"tokenami\" są poszczególne litery, a algorytm zajmuje bardzo dużo czasu. Gdy tokenami są całe słowa - zajmuje to mniej czasu. W niektórych przypadkach musimy zanegować uzyskaną \"odległość\" - gdy metryka maleje jak teksty są podobne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a206916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(lns):\n",
    "    lines = lns.copy()\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = lines[i].lower()\n",
    "    punctuation = \".,;/()[]\\n\\t\\\"':-+\"\n",
    "    for i in range(len(lines)):\n",
    "        for c in punctuation:\n",
    "            lines[i] = lines[i].replace(c, \"\").strip()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9ef3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(lns, stopwords):\n",
    "    lines = lns.copy()\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = lines[i].lower()\n",
    "    for w in stopwords:\n",
    "        lines[i] = lines[i].replace(f\"{w[0]}\", \" \")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e994ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lines.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    processed = remove_stopwords(process(lines), stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beca681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics import rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3a1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "nl = [line.split() for line in remove_stopwords(process(lines), stopwords)[:N]]\n",
    "# nl = lines[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1110fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(data, metric, mul=1):\n",
    "    aff_matrix = mul * np.array([[metric(w1, w2) for w2 in data] for w1 in data])\n",
    "    affprop = AffinityPropagation(affinity=\"precomputed\", damping=0.5)\n",
    "    affprop.fit(aff_matrix)\n",
    "    return affprop.labels_[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c65dd7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_clusters(labels):\n",
    "    for j in range(max(labels)+1):\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == j:\n",
    "                print(lines[i])\n",
    "        print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ca7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clusters.txt\", \"r\") as f:\n",
    "    correct = f.read().split(sep=\"##########\")\n",
    "for i in range(len(correct)):\n",
    "    correct[i] = correct[i].split(sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee0e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [None] * len(lines)\n",
    "for i in range(len(lines)):\n",
    "    for j in range(len(correct)):\n",
    "        if lines[i][:-1] in correct[j]:\n",
    "            true_labels[i] = j\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0837f4",
   "metadata": {},
   "source": [
    "Niestety dla tak dobranych metryk (spośród których najszybszą jest metryka dice), czas policzenia macierzy odległości pomiędzy każdymi dwoma stringami jest znaczny. Udało się policzyć jedynie dla maksymalnie 1000 linii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc30ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "nl = [line.split() for line in remove_stopwords(process(lines), stopwords)[:N]]\n",
    "lev_labels = get_labels(nl, levenstein, -1)\n",
    "dice_labels = get_labels(nl, dice)\n",
    "lcs_labels = get_labels(nl, lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "452c10ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9028571428571428\n",
      "0.9183673469387755\n",
      "0.9159183673469388\n"
     ]
    }
   ],
   "source": [
    "print(rand_index(lev_labels, true_labels))\n",
    "print(rand_index(dice_labels, true_labels))\n",
    "print(rand_index(lcs_labels, true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d547b5",
   "metadata": {},
   "source": [
    "Dla tekstów bez preprocessingu pojawia się problem. \"Tokenami\" są poszczególne litery, a co za tym idzie jest ich znacznie więcej. Powoduje to znaczny wzrost czasu działania algorytmów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c907c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "nl = [line for line in lines[:N]]\n",
    "lev_labels = get_labels(nl, levenstein, -1)\n",
    "dice_labels = get_labels(nl, dice)\n",
    "lcs_labels = get_labels(nl, lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda656e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8759183673469387\n",
      "0.8579591836734693\n",
      "0.8391836734693877\n"
     ]
    }
   ],
   "source": [
    "print(rand_index(lev_labels, true_labels))\n",
    "print(rand_index(dice_labels, true_labels))\n",
    "print(rand_index(lcs_labels, true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d3539",
   "metadata": {},
   "source": [
    "Porównując otrzymane wskaźniki między danymi które poddano preprocessingowi oraz nieobrobione, widzimy że lepsze wyniki otrzymano dla danych przetworzonych.\n",
    "Warto sprawdzić też większą liczbę linii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05e39deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piotr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:236: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "nl = [line.split() for line in remove_stopwords(process(lines), stopwords)[:N]]\n",
    "lev_labels = get_labels(nl, levenstein, -1)\n",
    "dice_labels = get_labels(nl, dice)\n",
    "lcs_labels = get_labels(nl, lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "392a6e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464646464646465\n",
      "0.9577777777777777\n",
      "0.9472727272727273\n"
     ]
    }
   ],
   "source": [
    "print(rand_index(lev_labels, true_labels))\n",
    "print(rand_index(dice_labels, true_labels))\n",
    "print(rand_index(lcs_labels, true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec2f12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "nl = [line for line in lines[:N]]\n",
    "lev_labels = get_labels(nl, levenstein, -1)\n",
    "dice_labels = get_labels(nl, dice)\n",
    "lcs_labels = get_labels(nl, lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef19e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9547474747474748\n",
      "0.9216161616161617\n",
      "0.9329292929292929\n"
     ]
    }
   ],
   "source": [
    "print(rand_index(lev_labels, true_labels))\n",
    "print(rand_index(dice_labels, true_labels))\n",
    "print(rand_index(lcs_labels, true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba35a93",
   "metadata": {},
   "source": [
    "Warto zauważyć że zastosowana metryka okazała się nie być najlepszym wyborem w tej sytuacji. Zwiększając liczbę elementów które klasteryzujemy, rośnie wartość metryki. Wynika to z faktu, że większość par elementów należy do różnych klastrów i pary te, które możemy uznać za \"true negative\" dominują nad parami pozytywnymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d52c668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piotr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:236: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N = 500\n",
    "nl = [line.split() for line in remove_stopwords(process(lines), stopwords)[:N]]\n",
    "lev_labels = get_labels(nl, levenstein, -1)\n",
    "dice_labels = get_labels(nl, dice)\n",
    "lcs_labels = get_labels(nl, lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf506b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9771703406813628\n",
      "0.9878877755511022\n",
      "0.9870140280561123\n"
     ]
    }
   ],
   "source": [
    "print(rand_index(lev_labels, true_labels))\n",
    "print(rand_index(dice_labels, true_labels))\n",
    "print(rand_index(lcs_labels, true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b4b08",
   "metadata": {},
   "source": [
    "Dla linii poddanym preprocessingowi jesteśmy w stanie sklasyfikować w sensownym czasie znacznie większą liczbę linii."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e9057",
   "metadata": {},
   "source": [
    "## Czy dałoby się zrobić lepiej?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48003f",
   "metadata": {},
   "source": [
    "Próbując poprawić uzyskane wyniki, należałoby większą uwagę zwrócić na poprawę czasu działania klasteryzacji. Tak dobranymi metodami nie udało się sklasyfikować wszystkich linii (z obserwacji czas klasyfikacji linii poddanych preprocessingowi całego pliku wynosiłby kilka/kilkanaście godzin).<br>\n",
    "Aby zwiększyć dokładność dobrym pomysłem mogłoby okazać się wyodrębnianie charakterystycznych elementów takich jak nr telefonu, fax, adres za pomocą specjalnie przygotowanych wyrażeń regularnych. Tak uzyskane dane mogłyby ze znacznie większą pewnością stwierdzić, czy dane elementy powinny należeć do jednego klastra."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
